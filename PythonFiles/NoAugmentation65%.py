
# coding: utf-8

# In[2]:


import tensorflow.keras


# In[3]:


import pandas as pd
import numpy as np
import os
import keras
import matplotlib.pyplot as plt
from keras.layers import Dense,GlobalAveragePooling2D
from keras.applications import MobileNet
from keras.preprocessing import image
from keras.applications.mobilenet import preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.optimizers import Adam
from keras.utils import plot_model
from keras.callbacks import ModelCheckpoint


# In[9]:


base_model=MobileNet(weights='imagenet',include_top=False)
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x)
x=Dense(1024,activation='relu')(x) 
x=Dense(512,activation='relu')(x)
preds=Dense(139,activation='softmax')(x) 


# In[10]:


model=Model(inputs=base_model.input,outputs=preds)
for layer in model.layers[:20]:
    layer.trainable=False
for layer in model.layers[20:]:
    layer.trainable=True


# In[11]:


train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.2)

train_generator=train_datagen.flow_from_directory('/home/ficiu/Desktop/Train_data (copy)',
                                                 target_size=(224,224),
                                                 color_mode='rgb',
                                                 batch_size=50,
                                                 class_mode='categorical',shuffle=True,subset='training')
validation_generator = train_datagen.flow_from_directory(
    '/home/ficiu/Desktop/Train_data (copy)', # same directory as training data
     target_size=(224,224),
    color_mode='rgb',
    batch_size=50,
    class_mode='categorical',shuffle=True,subset='validation')


# In[38]:


filepath="/home/ficiu/Desktop/keras/PrimuKerasweights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]


# In[41]:


model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])
step_size_train=train_generator.n//train_generator.batch_size
model.fit_generator(generator=train_generator,steps_per_epoch=step_size_train,epochs=100, validation_data = validation_generator, 
    validation_steps = validation_generator.samples // step_size_train,verbose=1,callbacks=callbacks_list)


# In[30]:





# In[21]:


plt.plot(model.history.history['acc'])
plt.title('model accuracy')
plt.ylabel('Percent')
plt.xlabel('Epoch')
plt.legend(['Accuracy', 'test'], loc='upper left')
plt.show()


# In[25]:


plt.plot(model.history.history['loss'])
plt.title('Loss')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(['Loss', 'test'], loc='upper left')
plt.show()


# In[34]:


model.save('/home/ficiu/Desktop/keras/keras_accuracy59')


# In[27]:


print(model.history.history['acc'])


# In[28]:


print(model.history.history['loss'])


# In[17]:


print(model.history.history['acc'])


# In[18]:


print(model.history.history['loss'])


# In[19]:


print(model.history.history)


# In[7]:


plt.plot([0.4280030401471453, 0.5733381037931874, 0.6537619054975633, 0.7079440334010675, 0.7434842864649249, 0.7794715890332718, 0.7937770992526797, 0.8225222345121993, 0.8421923131679272, 0.8531896764258224,0.862488260157358, 0.8748714693769633, 0.8841253471894643, 0.8920827893381802, 0.899056726350106, 0.9129151918986256, 0.9179221210830826, 0.9169833228059339, 0.9210067466430966, 0.9309759005425234, 0.9501989352681245, 0.9497965927831531, 0.9483213360758641, 0.9590504708860966, 0.9611515934676541, 0.9579775575351063, 0.9577093285411986, 0.959586927842708, 0.9581116719587833, 0.9617774595337745, 0.9642362190782957, 0.9635209435136335, 0.964459743557418, 0.9641468105363485, 0.961196297119106, 0.9694666733440765, 0.9671867330631001, 0.9668290937606093, 0.9625821452125034, 0.9681255329976356, 0.9693772632033639, 0.9690643316584879, 0.9729536434461404, 0.9721489575009507, 0.968349057210297, 0.9722830713064383, 0.9711207494587992, 0.9745183078373724, 0.9713889775200936, 0.9715677947611998, 0.9676784831067778, 0.9730877578698175, 0.9759041568394015, 0.9752782890173036, 0.9779158685261619, 0.9748759464737108, 0.9706289962921993, 0.9798381737333826, 0.9770664775226063, 0.9740265568610814, 0.9746524234841051, 0.9745183085035247, 0.9747865367193664, 0.9749206507566751, 0.9784523265725985, 0.9780946874886057, 0.9817157709378445, 0.9767982492188326, 0.9736242133608939, 0.9807322676289764, 0.9791228972121255, 0.9819839993002397, 0.9753676986730575, 0.980195810637725, 0.9769770691485296, 0.9818498839546078, 0.9805981522487045])
plt.plot([0.24000000084439913, 0.4150000015894572, 0.3133333312968413, 0.4999999950329463, 0.5416666716337204, 0.4466666653752327, 0.5500000069538752, 0.5216666683554649, 0.5191986631471446, 0.5700000002980232,0.4983333299557368, 0.5050000001986822, 0.49666666487852734, 0.5866666634877523, 0.5350000063578287, 0.5600000023841858, 0.5459098486550065, 0.56833333025376, 0.5716666653752327, 0.5916666612029076,0.6200000097354254, 0.4749999965230624, 0.56833333025376, 0.6166666646798452, 0.5993322294224085, 0.5633333300550779, 0.6033333341280619, 0.5866666634877523, 0.5666666676600774, 0.6233333349227905, 0.6100000018874804, 0.5933333337306976, 0.5983333388964335, 0.5375626029474707, 0.6016666640837988, 0.6050000041723251, 0.6133333345254263, 0.5766666680574417, 0.596666673819224, 0.5733333354194959, 0.605000006655852, 0.6066666692495346, 0.5959933296666917, 0.6016666740179062, 0.5916666736205419, 0.6266666725277901, 0.5816666831572851, 0.6283333376049995, 0.6149999971191088, 0.5666666726271311, 0.5683333401878675, 0.5733333354194959, 0.6193656134286986, 0.6083333467443784, 0.5716666678587595, 0.6183333247900009, 0.6100000043710073, 0.6350000003973643, 0.6266666700442632, 0.5816666707396507, 0.621666669845581, 0.6277128518722292, 0.5450000017881393, 0.5599999949336052, 0.5733333279689153, 0.6116666694482168, 0.616666667163372, 0.6433333456516266, 0.578333335618178, 0.6450000057617823, 0.6176961617597156, 0.6083333392937978, 0.5816666682561239, 0.6100000043710073, 0.6200000047683716, 0.6116666744152705, 0.5283333361148834])
plt.title('Model accuracy')
plt.ylabel('Percent')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()


# In[6]:


plt.plot([2.0753079387764215, 1.4435393522387832, 1.14132908785624, 0.9495398003322042, 0.8228998232113777, 0.6985452587688511, 0.6437915211948212, 0.5605256123346457, 0.4886178848750793, 0.46337755295224053,0.44212523906206624, 0.3968547358019766, 0.36301707879965867, 0.34110992456029793, 0.32155980009630086, 0.2768274356825366, 0.269453632806726, 0.2643677356662783, 0.2577607091097413, 0.2260725558977535,0.17762146991949415, 0.1769486998991304, 0.17962120672085602, 0.14668019007845784, 0.13732617137720235, 0.15136072111170804, 0.14763702182478514, 0.1379295554987307, 0.1418980830076114, 0.13372970498654518, 0.12215377069961246, 0.13191973391436618, 0.12120589699557738, 0.12272273548059986, 0.1327031779528819, 0.10824459567120016, 0.11528742499009394, 0.11581977927323962, 0.1314647267813021, 0.12154323367441594, 0.10551871290767915, 0.10542835913712366, 0.09809701419565861, 0.09655760935101945, 0.11542730559329092, 0.10179011743957202, 0.10234213066602409, 0.09501131401710212, 0.10483077843645423, 0.10096295604665402, 0.11824426238213032, 0.09725187599283507, 0.0839338427094627, 0.08769218542186981, 0.07570725668078328, 0.09167783409264903, 0.10825998041658229, 0.07265324677621761, 0.0864325874235284, 0.10035592313053422, 0.09098321292312055, 0.0913519316996917, 0.09528317080260966, 0.09358235608956296, 0.08072370236250914, 0.08165226160595924, 0.06699905662568381, 0.08572522567516226, 0.09442116509338942, 0.0709960523614431, 0.0731137185267008, 0.06667953272229558, 0.0933528760894795, 0.07401664453254005, 0.08588556834668758, 0.06517268074498303, 0.0731042786933176])
plt.plot([3.7267205715179443, 2.3758082588513694, 3.123230457305908, 2.0276504258314767, 1.8454862038294475, 2.545332670211792, 1.9231875737508137, 2.0159170627593994, 2.113188080477197, 1.908180445432663,2.623856554428736, 2.3775475919246674, 2.667656809091568, 2.0195261339346566, 2.303461710611979, 2.27858766913414, 2.3683499099814234, 2.153103897968928, 2.2426971395810447, 2.4175097246964774,2.0919979910055795, 3.3277969360351562, 2.5075389742851257, 2.3476240932941437, 2.458773995480673, 2.4557916621367135, 2.2352971136569977, 2.2780965069929757, 2.800012618303299, 2.086111009120941, 2.4292068779468536, 2.391942967971166, 2.3324227134386697, 2.965457089954306, 2.4614464938640594, 2.6625950833161673, 2.3931919038295746, 2.3816697895526886, 2.5102548400561013, 2.53261465827624, 2.6861790915330253, 2.5127513110637665, 2.578148215362345, 2.705101430416107, 2.3732640047868094, 2.472604771455129, 2.656492988268534, 2.182323763767878, 2.1861333648363748, 2.655303200085958, 2.6428268452485404, 2.364872694015503, 2.4622951158896114, 2.467888722817103, 2.504956622918447, 2.5314623614152274, 2.3769041895866394, 2.3517612715562186, 2.1343866487344108, 2.3915141423543296, 2.4914631942907968, 2.2780945874215766, 3.003523608048757, 2.8045765856901803, 2.4809893469015756, 2.396760582923889, 2.5261655847231546, 2.022110531727473, 2.729510804017385, 2.324283222357432, 2.649510161108485, 2.732434650262197, 2.763237218062083, 2.6264687875906625, 2.597906698783239, 2.6653564671675363, 3.6459155480066934])
plt.title('Loss')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()


# In[28]:


print(model.history.history)


# In[40]:


print(model.history.history)


# In[42]:


print(model.history.history)

